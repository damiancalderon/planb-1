{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Packaging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1654,
     "status": "ok",
     "timestamp": 1735223939227,
     "user": {
      "displayName": "Enrique Gonzalez",
      "userId": "11537615501324889345"
     },
     "user_tz": 360
    },
    "id": "9U2nJ2tkCcfK"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np # to use numpy arrays instead of lists\n",
    "import pandas as pd # DataFrame (table)\n",
    "import matplotlib.pyplot as plt # to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# Ensure project root (one level up from notebooks/) is in sys.path so `models` can be imported\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from models.analysis_modules import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Working on Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_file = \"C:/Users/dark_/OneDrive/Documentos/01_Escuela/09_Septimo semestre/llamenadios/data/raw/synthetic_coffee_health_10000.csv\"\n",
    "datos = pd.read_csv(data_file, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom analysis modules\n",
    "import sys\n",
    "sys.path.append('../models')\n",
    "from analysis_modules import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Age  Coffee_Intake  Caffeine_mg  Sleep_Hours   BMI  Heart_Rate  \\\n",
      "0   1   40            3.5        328.1          7.5  24.9          78   \n",
      "1   2   33            1.0         94.1          6.2  20.0          67   \n",
      "2   3   42            5.3        503.7          5.9  22.7          59   \n",
      "3   4   53            2.6        249.2          7.3  24.7          71   \n",
      "4   5   32            3.1        298.0          5.3  24.1          76   \n",
      "\n",
      "   Physical_Activity_Hours  Smoking  Alcohol_Consumption  SQ_Low  SQ_Fair  \\\n",
      "0                     14.5        0                    0       0        0   \n",
      "1                     11.0        0                    0       0        0   \n",
      "2                     11.2        0                    0       0        1   \n",
      "3                      6.6        0                    0       0        0   \n",
      "4                      8.5        0                    1       0        1   \n",
      "\n",
      "   SQ_Good  SQ_Excellent  \n",
      "0        1             0  \n",
      "1        1             0  \n",
      "2        0             0  \n",
      "3        1             0  \n",
      "4        0             0  \n",
      "\n",
      "       ID       Age  Coffee_Intake  Caffeine_mg  Sleep_Hours       BMI  \\\n",
      "0  0.0000  0.354839       0.426829     0.420479     0.642857  0.426724   \n",
      "1  0.0001  0.241935       0.121951     0.120595     0.457143  0.215517   \n",
      "2  0.0002  0.387097       0.646341     0.645521     0.414286  0.331897   \n",
      "3  0.0003  0.564516       0.317073     0.319364     0.614286  0.418103   \n",
      "4  0.0004  0.225806       0.378049     0.381904     0.328571  0.392241   \n",
      "\n",
      "   Heart_Rate  Physical_Activity_Hours  Smoking  Alcohol_Consumption  SQ_Low  \\\n",
      "0    0.474576                 0.966667      0.0                  0.0     0.0   \n",
      "1    0.288136                 0.733333      0.0                  0.0     0.0   \n",
      "2    0.152542                 0.746667      0.0                  0.0     0.0   \n",
      "3    0.355932                 0.440000      0.0                  0.0     0.0   \n",
      "4    0.440678                 0.566667      0.0                  1.0     0.0   \n",
      "\n",
      "   SQ_Fair  SQ_Good  SQ_Excellent  \n",
      "0      0.0      1.0           0.0  \n",
      "1      0.0      1.0           0.0  \n",
      "2      1.0      0.0           0.0  \n",
      "3      0.0      1.0           0.0  \n",
      "4      1.0      0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "dataSelected = selectData(datos)\n",
    "print(dataSelected.head())\n",
    "print()\n",
    "dataPreprocessed = preprocess(dataSelected)\n",
    "print(dataPreprocessed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. ML Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "            ID       Age  Coffee_Intake  Caffeine_mg  Sleep_Hours       BMI  \\\n",
      "2967  0.296730  0.161290       0.353659     0.347943     0.371429  0.172414   \n",
      "700   0.070007  0.161290       0.451220     0.446623     0.485714  0.370690   \n",
      "3481  0.348135  0.000000       0.048780     0.049981     0.314286  0.512931   \n",
      "1621  0.162116  0.000000       0.439024     0.435089     0.442857  0.737069   \n",
      "800   0.080008  0.451613       0.609756     0.608356     0.400000  0.271552   \n",
      "\n",
      "      Heart_Rate  Physical_Activity_Hours  Smoking  Alcohol_Consumption  \\\n",
      "2967    0.067797                 0.046667      0.0                  1.0   \n",
      "700     0.508475                 0.366667      0.0                  1.0   \n",
      "3481    0.406780                 0.093333      0.0                  1.0   \n",
      "1621    0.677966                 0.226667      0.0                  1.0   \n",
      "800     0.084746                 0.906667      0.0                  0.0   \n",
      "\n",
      "      SQ_Low  SQ_Fair  SQ_Good  SQ_Excellent  \n",
      "2967     0.0      1.0      0.0           0.0  \n",
      "700      0.0      0.0      1.0           0.0  \n",
      "3481     0.0      1.0      0.0           0.0  \n",
      "1621     0.0      0.0      1.0           0.0  \n",
      "800      0.0      1.0      0.0           0.0  \n",
      "Test set\n",
      "            ID       Age  Coffee_Intake  Caffeine_mg  Sleep_Hours       BMI  \\\n",
      "9394  0.939494  0.306452       0.341463     0.345764     0.457143  0.262931   \n",
      "898   0.089809  0.500000       0.524390     0.524670     0.328571  0.245690   \n",
      "2398  0.239824  0.306452       0.512195     0.511726     0.228571  0.107759   \n",
      "5906  0.590659  0.225806       0.195122     0.196847     0.357143  0.741379   \n",
      "2343  0.234323  0.161290       0.182927     0.178777     0.600000  0.625000   \n",
      "\n",
      "      Heart_Rate  Physical_Activity_Hours  Smoking  Alcohol_Consumption  \\\n",
      "9394    0.406780                 0.353333      0.0                  0.0   \n",
      "898     0.305085                 0.506667      1.0                  1.0   \n",
      "2398    0.322034                 0.860000      0.0                  1.0   \n",
      "5906    0.491525                 0.346667      0.0                  0.0   \n",
      "2343    0.440678                 0.033333      1.0                  0.0   \n",
      "\n",
      "      SQ_Low  SQ_Fair  SQ_Good  SQ_Excellent  \n",
      "9394     0.0      0.0      1.0           0.0  \n",
      "898      0.0      1.0      0.0           0.0  \n",
      "2398     0.0      0.0      0.0           0.0  \n",
      "5906     0.0      1.0      0.0           0.0  \n",
      "2343     0.0      0.0      1.0           0.0  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ts_size = .25\n",
    "[trainSet, testSet] = splitDataSet(dataPreprocessed, test_size=ts_size, randSplit=True)\n",
    "print(\"Train set\")\n",
    "print(trainSet.head())\n",
    "print\n",
    "print(\"Test set\")\n",
    "print(testSet.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Implement Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SQ_Low', 'SQ_Fair', 'SQ_Good', 'SQ_Excellent'], dtype='object')\n",
      "Index(['ID', 'Age', 'Coffee_Intake', 'Caffeine_mg', 'Sleep_Hours', 'BMI',\n",
      "       'Heart_Rate', 'Physical_Activity_Hours', 'Smoking',\n",
      "       'Alcohol_Consumption'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataPreprocessed.columns[-4:])\n",
    "print(dataPreprocessed.columns[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "def metodosML(dataSet=0, dataSet2=0):\n",
    "    \"\"\"\n",
    "    Function to perform classification using various machine learning methods.\n",
    "    \"\"\"\n",
    "\n",
    "    methodsUsed = ['DT', 'RF', 'KNN']\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    trainModelMetrics = pd.DataFrame(index=methodsUsed, columns=metrics)\n",
    "    testModelMetrics = pd.DataFrame(index=methodsUsed, columns=metrics)\n",
    "    timeHeaders=['Fit Time (sec)']\n",
    "    compTime = pd.DataFrame(index=methodsUsed, columns=timeHeaders)\n",
    "    compTime.index.name = \"Computation Time\"\n",
    "\n",
    "    yVar = dataSet.columns[-4:]\n",
    "    trainModel = pd.DataFrame()\n",
    "    testModel = pd.DataFrame()\n",
    "    trainModel[yVar] = dataSet[yVar]\n",
    "    testModel[yVar] = dataSet2[yVar]\n",
    "    sizeData=len(dataSet.columns)-4\n",
    "\n",
    "\n",
    "    def computeModels(model=0, param_search=0, model_name='', position=0):\n",
    "        \"\"\"\n",
    "        Function to compute a model using GridSearchCV and evaluate it.\n",
    "        \"\"\"\n",
    "\n",
    "        start = tm.time() \n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_search, cv=5, verbose=1)\n",
    "        grid_search.fit(dataSet.iloc[:,:-4].to_numpy().reshape(len(dataSet),sizeData), dataSet.iloc[:,-4:].to_numpy().reshape(len(dataSet),4))\n",
    "        best_model_param = grid_search.best_estimator_\n",
    "        end = tm.time()\n",
    "        lspTime = end - start\n",
    "        \n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print(grid_search.best_params_)\n",
    "        print() \n",
    "    \n",
    "        compTime.iloc[position, 0] = lspTime\n",
    "        computeResults(best_model_param, model_name, position)\n",
    "    \n",
    "    def computeResults(train_model_param=0, model_name='', position=0):\n",
    "        \"\"\" \n",
    "        Function to compute results for the classification models.\n",
    "        \"\"\"\n",
    "        nonlocal trainModel, testModel, trainModelMetrics, testModelMetrics\n",
    "\n",
    "        columnsNames = [model_name + ' SQ_Low',  model_name + ' SQ_Fair',  model_name + ' SQ_Good',  model_name + ' SQ_Excellent']\n",
    "\n",
    "        trainModel[columnsNames] = train_model_param.predict(dataSet.iloc[:,:-4].to_numpy().reshape(len(dataSet),sizeData))\n",
    "        testModel[columnsNames] = train_model_param.predict(dataSet2.iloc[:,:-4].to_numpy().reshape(len(dataSet2),sizeData))\n",
    "        #print(trainModel.head())\n",
    "        #print()\n",
    "        #print(testModel.head())\n",
    "        print()\n",
    "       \n",
    "        trainModelMetrics.iloc[position, 0] = accuracy_score(trainModel[yVar].to_numpy().reshape(len(dataSet),4), trainModel[columnsNames].to_numpy().reshape(len(dataSet),4))\n",
    "        trainModelMetrics.iloc[position, 1] = precision_score(trainModel[yVar].to_numpy().reshape(len(dataSet),4), trainModel[columnsNames].to_numpy().reshape(len(dataSet),4), average='macro', zero_division=0)\n",
    "        trainModelMetrics.iloc[position, 2] = recall_score(trainModel[yVar].to_numpy().reshape(len(dataSet),4), trainModel[columnsNames].to_numpy().reshape(len(dataSet),4), average='macro', zero_division=0)\n",
    "        trainModelMetrics.iloc[position, 3] = f1_score(trainModel[yVar].to_numpy().reshape(len(dataSet),4), trainModel[columnsNames].to_numpy().reshape(len(dataSet),4), average='macro', zero_division=0)\n",
    "\n",
    "        testModelMetrics.iloc[position, 0] = accuracy_score(testModel[yVar].to_numpy().reshape(len(dataSet2),4), testModel[columnsNames].to_numpy().reshape(len(dataSet2),4))\n",
    "        testModelMetrics.iloc[position, 1] = precision_score(testModel[yVar].to_numpy().reshape(len(dataSet2),4), testModel[columnsNames].to_numpy().reshape(len(dataSet2),4), average='macro', zero_division=0)\n",
    "        testModelMetrics.iloc[position, 2] = recall_score(testModel[yVar].to_numpy().reshape(len(dataSet2),4), testModel[columnsNames].to_numpy().reshape(len(dataSet2),4), average='macro', zero_division=0)\n",
    "        testModelMetrics.iloc[position, 3] = f1_score(testModel[yVar].to_numpy().reshape(len(dataSet2),4), testModel[columnsNames].to_numpy().reshape(len(dataSet2),4), average='macro', zero_division=0)\n",
    "\n",
    "\n",
    "    # Decision Tree Classifier\n",
    "    print('Classification with DT')\n",
    "    dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "    param_search_dt_clf = {\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_depth': [5, 10, 15, 20, 25, 30, None],\n",
    "        'max_leaf_nodes': [5, 10, 15, 20, 35, None]\n",
    "    }\n",
    "    computeModels(dt_clf, param_search_dt_clf, 'DT', 0)\n",
    "\n",
    "    # Random Forest Classifier\n",
    "    print('Classification with RF')\n",
    "    rf_clf = RandomForestClassifier(random_state=0)\n",
    "    param_search_rf_clf = {\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [5, 10, None],\n",
    "        'max_leaf_nodes': [5, 10, None]\n",
    "    }\n",
    "    computeModels(rf_clf, param_search_rf_clf, 'RF', 1)\n",
    "\n",
    "    # Support Vector Classifier\n",
    "    # does not support multi-label classification directly\n",
    "    print('Classification with SVC')\n",
    "    svc_clf = SVC(random_state=0)\n",
    "    param_search_svc_clf = {\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "    #computeModels(svc_clf, param_search_svc_clf, 'SVC', 2)\n",
    "\n",
    "    # Gradient Boosting Classifier\n",
    "    # does not support multi-label classification directly\n",
    "    print('Classification with GB')\n",
    "    gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "    param_search_gb_clf = {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    }\n",
    "    #computeModels(gb_clf, param_search_gb_clf, 'GB', 3)\n",
    "\n",
    "    # K-Nearest Neighbors Classifier\n",
    "    print('Classification with KNN')\n",
    "    knn_clf = KNeighborsClassifier()\n",
    "    param_search_knn_clf = {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "    computeModels(knn_clf, param_search_knn_clf, 'KNN', 2)\n",
    "\n",
    "    print(\"=======================================================================\")\n",
    "    print(\"                      FIT TIME COMPARISON\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"                      Training\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(compTime)\n",
    "    print(\"=======================================================================\")\n",
    "    print(\"                      MODEL PERFORMANCE COMPARISON\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"                      Training\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(trainModelMetrics)\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"                      Testing\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(testModelMetrics)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification with DT\n",
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "Best parameters set found on development set:\n",
      "{'criterion': 'gini', 'max_depth': 20, 'max_leaf_nodes': None}\n",
      "\n",
      "\n",
      "Classification with RF\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters set found on development set:\n",
      "{'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': None, 'n_estimators': 50}\n",
      "\n",
      "\n",
      "Classification with SVC\n",
      "Classification with GB\n",
      "Classification with KNN\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best parameters set found on development set:\n",
      "{'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "\n",
      "\n",
      "=======================================================================\n",
      "                      FIT TIME COMPARISON\n",
      "-----------------------------------------------------------------------\n",
      "                      Training\n",
      "-----------------------------------------------------------------------\n",
      "                 Fit Time (sec)\n",
      "Computation Time               \n",
      "DT                     6.290341\n",
      "RF                     88.29425\n",
      "KNN                   10.557997\n",
      "=======================================================================\n",
      "                      MODEL PERFORMANCE COMPARISON\n",
      "-----------------------------------------------------------------------\n",
      "                      Training\n",
      "-----------------------------------------------------------------------\n",
      "    accuracy precision recall    f1\n",
      "DT       1.0      0.75   0.75  0.75\n",
      "RF       1.0      0.75   0.75  0.75\n",
      "KNN      1.0      0.75   0.75  0.75\n",
      "-----------------------------------------------------------------------\n",
      "                      Testing\n",
      "-----------------------------------------------------------------------\n",
      "    accuracy precision    recall        f1\n",
      "DT    0.9708  0.721741  0.724571  0.723141\n",
      "RF     0.972  0.722197  0.731528  0.726755\n",
      "KNN   0.7488  0.567079  0.489209  0.515919\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metodosML(trainSet, testSet)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOMirmAiOle0GYl1sHdb5Nv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
